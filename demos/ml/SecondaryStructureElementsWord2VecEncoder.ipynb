{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Secondary Structure Elements Word2Vec Encoder Demo\n",
    "\n",
    "This demo creates a dataset by extracting secondary structure elements \"H\", then encode an overlapping Ngram feature vector\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from mmtfPyspark.ml import ProteinSequenceEncoder\n",
    "from mmtfPyspark.mappers import StructureToPolymerChains\n",
    "from mmtfPyspark.filters import ContainsLProteinChain\n",
    "from mmtfPyspark.datasets import secondaryStructureElementExtractor\n",
    "from mmtfPyspark.webfilters import Pisces\n",
    "from mmtfPyspark.io import mmtfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure Spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"SecondaryStructureElementsWord2VecEncoder\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Read MMTF Hadoop sequence file and \n",
    " \n",
    " Create a non-redundant set(<=20% seq. identity) of L-protein chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../resources/mmtf_reduced_sample/\"\n",
    "fraction = 0.05\n",
    "seed = 123\n",
    "\n",
    "pdb = mmtfReader \\\n",
    "        .read_sequence_file(path) \\\n",
    "        .flatMap(StructureToPolymerChains(False, True)) \\\n",
    "        .filter(ContainsLProteinChain()) \\\n",
    "        .sample(False, fraction, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Element \"H\" from Secondary Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data   : 3417\n",
      "+--------------------+-----+\n",
      "|sequence            |label|\n",
      "+--------------------+-----+\n",
      "|STALNERI            |H    |\n",
      "|RAWVKLISSHDKLVSDLVRR|H    |\n",
      "|EQAVRCGIELQRALRRN   |H    |\n",
      "|NVAMAARVAAQ         |H    |\n",
      "|PVRDA               |H    |\n",
      "|NKMEEKAPLLLQEDFNM   |H    |\n",
      "|KLKVAWEEAKKRWNNI    |H    |\n",
      "|FHGTALVAY           |H    |\n",
      "|AVDFNRAVR           |H    |\n",
      "|AFHYYLTRALQL        |H    |\n",
      "+--------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = \"H\"\n",
    "data = secondaryStructureElementExtractor.get_dataset(pdb, label).cache()\n",
    "print(f\"original data   : {data.count()}\")\n",
    "data.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec encoded feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+\n",
      "|            sequence|label|               ngram|            features|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "|            STALNERI|    H|[ST, TA, AL, LN, ...|[-0.1606897578707...|\n",
      "|RAWVKLISSHDKLVSDLVRR|    H|[RA, AW, WV, VK, ...|[-0.2602296720602...|\n",
      "|   EQAVRCGIELQRALRRN|    H|[EQ, QA, AV, VR, ...|[-0.0787890475476...|\n",
      "|         NVAMAARVAAQ|    H|[NV, VA, AM, MA, ...|[0.14959662854671...|\n",
      "|               PVRDA|    H|    [PV, VR, RD, DA]|[-0.1039832192473...|\n",
      "+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "segmentLength = 11\n",
    "n = 2\n",
    "windowSize = (segmentLength-1)/2\n",
    "vectorSize = 50\n",
    "\n",
    "encoder = ProteinSequenceEncoder(data)\n",
    "# overlapping_ngram_word2vec_encode uses keyword attributes\n",
    "data = encoder.overlapping_ngram_word2vec_encode(n=n, windowSize=windowSize, vectorSize=vectorSize)\n",
    "\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminate Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
